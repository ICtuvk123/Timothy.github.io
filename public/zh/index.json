[{"content":"","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"","title":""},{"content":"","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"","title":""},{"content":"date = \u0026lsquo;2026-01-15T15:08:59+08:00\u0026rsquo; draft = false tags = [\u0026lsquo;介绍\u0026rsquo;, \u0026lsquo;欢迎\u0026rsquo;] title = \u0026lsquo;第一篇文章\u0026rsquo; [cover] image = \u0026ldquo;/picture/car.png\u0026rdquo; alt = \u0026ldquo;Car Diagram\u0026rdquo; caption = \u0026ldquo;Visual representation of the car\u0026rdquo; relative = false +++\n欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003edate = \u0026lsquo;2026-01-15T15:08:59+08:00\u0026rsquo;\ndraft = false\ntags = [\u0026lsquo;介绍\u0026rsquo;, \u0026lsquo;欢迎\u0026rsquo;]\ntitle = \u0026lsquo;第一篇文章\u0026rsquo;\n[cover]\nimage = \u0026ldquo;/picture/car.png\u0026rdquo;\nalt = \u0026ldquo;Car Diagram\u0026rdquo;\ncaption = \u0026ldquo;Visual representation of the car\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":""},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"","title":""},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo; draft = false math = true tags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;] title = \u0026lsquo;几何深度学习简介\u0026rsquo; [cover] image = \u0026ldquo;/picture/car.png\u0026rdquo; relative = false +++\n几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003cp\u003edate = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo;\ndraft = false\nmath = true\ntags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;]\ntitle = \u0026lsquo;几何深度学习简介\u0026rsquo;\n[cover]\nimage = \u0026ldquo;/picture/car.png\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e","title":""},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo; draft = false math = true tags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;] title = \u0026lsquo;几何深度学习简介\u0026rsquo; [cover] image = \u0026ldquo;/picture/car.png\u0026rdquo; relative = false +++\n几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003cp\u003edate = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo;\ndraft = false\nmath = true\ntags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;]\ntitle = \u0026lsquo;几何深度学习简介\u0026rsquo;\n[cover]\nimage = \u0026ldquo;/picture/car.png\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e","title":""},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo; draft = false math = true tags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;] title = \u0026lsquo;几何深度学习简介\u0026rsquo; [cover] image = \u0026ldquo;/picture/car.png\u0026rdquo; relative = false +++\n几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003cp\u003edate = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo;\ndraft = false\nmath = true\ntags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;]\ntitle = \u0026lsquo;几何深度学习简介\u0026rsquo;\n[cover]\nimage = \u0026ldquo;/picture/car.png\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e","title":""},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo; draft = false math = true tags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;] title = \u0026lsquo;几何深度学习简介\u0026rsquo; [cover] image = \u0026ldquo;/picture/car.png\u0026rdquo; relative = false +++\n几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003cp\u003edate = \u0026lsquo;2026-01-17T02:53:59+08:00\u0026rsquo;\ndraft = false\nmath = true\ntags = [\u0026lsquo;geometric deep learning\u0026rsquo;, \u0026lsquo;machine learning\u0026rsquo;]\ntitle = \u0026lsquo;几何深度学习简介\u0026rsquo;\n[cover]\nimage = \u0026ldquo;/picture/car.png\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼构建了非欧几里得几何的例子。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"","title":""},{"content":"","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = 2026-01-16T10:00:00+08:00 title = \u0026ldquo;种群方法\u0026rdquo; description = \u0026ldquo;深入探讨种群方法\u0026rdquo; tags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;] math = true [cover] image = \u0026ldquo;/picture/population_cover.png\u0026rdquo; alt = \u0026ldquo;Population Method Diagram\u0026rdquo; caption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo; relative = false +++\n本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003edate = 2026-01-16T10:00:00+08:00\ntitle = \u0026ldquo;种群方法\u0026rdquo;\ndescription = \u0026ldquo;深入探讨种群方法\u0026rdquo;\ntags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;]\nmath = true\n[cover]\nimage = \u0026ldquo;/picture/population_cover.png\u0026rdquo;\nalt = \u0026ldquo;Population Method Diagram\u0026rdquo;\ncaption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e","title":""},{"content":"","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = 2026-01-16T10:00:00+08:00 title = \u0026ldquo;种群方法\u0026rdquo; description = \u0026ldquo;深入探讨种群方法\u0026rdquo; tags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;] math = true [cover] image = \u0026ldquo;/picture/population_cover.png\u0026rdquo; alt = \u0026ldquo;Population Method Diagram\u0026rdquo; caption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo; relative = false +++\n本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003edate = 2026-01-16T10:00:00+08:00\ntitle = \u0026ldquo;种群方法\u0026rdquo;\ndescription = \u0026ldquo;深入探讨种群方法\u0026rdquo;\ntags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;]\nmath = true\n[cover]\nimage = \u0026ldquo;/picture/population_cover.png\u0026rdquo;\nalt = \u0026ldquo;Population Method Diagram\u0026rdquo;\ncaption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e","title":""},{"content":"date = 2026-01-16T10:00:00+08:00 draft = false tags = [\u0026lsquo;强化学习\u0026rsquo;, \u0026lsquo;人工智能\u0026rsquo;, \u0026lsquo;机器学习\u0026rsquo;] title = \u0026lsquo;强化学习简介\u0026rsquo; math = true [cover] image = \u0026ldquo;/picture/reinforcement_learning01.png\u0026rdquo; alt = \u0026ldquo;Reinforcement Learning Diagram\u0026rdquo; caption = \u0026ldquo;强化学习概念概览\u0026rdquo; relative = false +++\n简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003cp\u003edate = 2026-01-16T10:00:00+08:00\ndraft = false\ntags = [\u0026lsquo;强化学习\u0026rsquo;, \u0026lsquo;人工智能\u0026rsquo;, \u0026lsquo;机器学习\u0026rsquo;]\ntitle = \u0026lsquo;强化学习简介\u0026rsquo;\nmath = true\n[cover]\nimage = \u0026ldquo;/picture/reinforcement_learning01.png\u0026rdquo;\nalt = \u0026ldquo;Reinforcement Learning Diagram\u0026rdquo;\ncaption = \u0026ldquo;强化学习概念概览\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"date = 2026-01-16T10:00:00+08:00 title = \u0026ldquo;种群方法\u0026rdquo; description = \u0026ldquo;深入探讨种群方法\u0026rdquo; tags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;] math = true [cover] image = \u0026ldquo;/picture/population_cover.png\u0026rdquo; alt = \u0026ldquo;Population Method Diagram\u0026rdquo; caption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo; relative = false +++\n本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003edate = 2026-01-16T10:00:00+08:00\ntitle = \u0026ldquo;种群方法\u0026rdquo;\ndescription = \u0026ldquo;深入探讨种群方法\u0026rdquo;\ntags = [\u0026ldquo;编程\u0026rdquo;, \u0026ldquo;种群方法\u0026rdquo;, \u0026ldquo;数学建模\u0026rdquo;]\nmath = true\n[cover]\nimage = \u0026ldquo;/picture/population_cover.png\u0026rdquo;\nalt = \u0026ldquo;Population Method Diagram\u0026rdquo;\ncaption = \u0026ldquo;优化中各种种群方法的概述\u0026rdquo;\nrelative = false\n+++\u003c/p\u003e\n\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e","title":""},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\r\n\r\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\r\n\r\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e值得注意的是，深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数感兴趣的任务并不是通用的，并且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数 $L: \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$：\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(\\dot,\\dot)$,\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(\\dot,\\dot)$,\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$,\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$,\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathellipsis{R} = \\mathbb{E}_{(x,y) \\sim P}[L(f(x), y)]$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathellipsis{R} = \\mathbb{E}_{(x,y) \\sim P}[L(f(x), y)]$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(f(x), y)]$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(f(x), y)]$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个映射: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{f \\in \\mathcal{F}} c(f) \\quad s.t. \\quad f(x_i) = y_i, \\quad i = 1, . . . , N$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个映射:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{f \\in \\mathcal{F}} c(f) \\quad s.t. \\quad f(x_i) = y_i, \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个映射: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{f \\in \\mathcal{F}} c(f) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个映射:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{f \\in \\mathcal{F}} c(f) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间，我们可以使用泛函分析中的工具来研究它们的性质。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} -\\frac{1}{2} \u0026amp; -\\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \u0026amp; -\\frac{1}{2} \\end{pmatrix}, \\begin{pmatrix} -\\frac{1}{2} \u0026amp; \\frac{\\sqrt{3}}{2} \\\\ -\\frac{\\sqrt{3}}{2} \u0026amp; -\\frac{1}{2} \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; -1 \\end{pmatrix}, \\begin{pmatrix} -\\frac{1}{2} \u0026amp; \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \u0026amp; \\frac{1}{2} \\end{pmatrix}, \\begin{pmatrix} -\\frac{1}{2} \u0026amp; -\\frac{\\sqrt{3}}{2} \\\\ -\\frac{\\sqrt{3}}{2} \u0026amp; \\frac{1}{2} \\end{pmatrix} \\right\\}$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$D_3 = \\left{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right}$$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right} $$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left{ \\left(\\begin{array}{ccc} 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 2 \u0026amp; 3 \\end{array}\\right), \\left(\\begin{array}{ccc} 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 3 \u0026amp; 1 \\end{array}\\right), \\dots \\right} $$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right\\} $$\n","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right\\} $$\n参考资料 Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., \u0026amp; Vandergheynst, P. (2017). Geometric deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine, 34(4), 18-42. Goodfellow, I., Bengio, Y., \u0026amp; Courville, A. (2016). Deep learning. MIT press. Cohen, T. S., \u0026amp; Welling, M. (2016). Group equivariant convolutional networks. In International conference on machine learning (pp. 2990-2999). PMLR. Kondor, R., \u0026amp; Trivedi, S. (2018). On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International conference on machine learning (pp. 2747-2755). PMLR. Wood, T., \u0026amp; Shawe-Taylor, J. (1996). Representation theory and invariant neural networks. Neural computation, 8(5), 1003-1013. Mallat, S. (2016). Understanding deep convolutional networks. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150203. Lee, J. M. (2013). Introduction to smooth manifolds. Springer Science \u0026amp; Business Media. ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right\\} $$\n参考资料 Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., \u0026amp; Vandergheynst, P. (2017). Geometric deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine, 34(4), 18-42. Goodfellow, I., Bengio, Y., \u0026amp; Courville, A. (2016). Deep learning. MIT press. Cohen, T. S., \u0026amp; Welling, M. (2016). Group equivariant convolutional networks. In International conference on machine learning (pp. 2990-2999). PMLR. Kondor, R., \u0026amp; Trivedi, S. (2018). On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International conference on machine learning (pp. 2747-2755). PMLR. Wood, T., \u0026amp; Shawe-Taylor, J. (1996). Representation theory and invariant neural networks. Neural computation, 8(5), 1003-1013. Mallat, S. (2016). Understanding deep convolutional networks. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150203. Lee, J. M. (2013). Introduction to smooth manifolds. Springer Science \u0026amp; Business Media. ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right\\} $$\n参考资料 Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., \u0026amp; Vandergheynst, P. (2017). Geometric deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine, 34(4), 18-42. Goodfellow, I., Bengio, Y., \u0026amp; Courville, A. (2016). Deep learning. MIT press. Cohen, T. S., \u0026amp; Welling, M. (2016). Group equivariant convolutional networks. In International conference on machine learning (pp. 2990-2999). PMLR. Kondor, R., \u0026amp; Trivedi, S. (2018). On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International conference on machine learning (pp. 2747-2755). PMLR. Wood, T., \u0026amp; Shawe-Taylor, J. (1996). Representation theory and invariant neural networks. Neural computation, 8(5), 1003-1013. Mallat, S. (2016). Understanding deep convolutional networks. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150203. Lee, J. M. (2013). Introduction to smooth manifolds. Springer Science \u0026amp; Business Media. ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"},{"content":"几何深度学习的演变 几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\n到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\n年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\n深度学习简介 深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\n几何深度学习的目标 虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\n这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\n高维学习 监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\n让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\n现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\n学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$： $$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\n这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数: $$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为： $$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\n所以，我们不仅希望函数拟合度好，同时也希望函数的复杂度低。这样的复杂度函数，我们把它称为函数的范数。 这样定义的好处是$\\mathcal{F}$变成了Banach空间(配备有范数的完备的向量空间)，我们可以使用泛函分析中的工具来研究它们的性质。\n几何先验 为了克服高维数据的“维度灾难”，我们必须利用数据的物理特性（对称性和尺度分离）；虽然数据的几何形状（Domain）可能很复杂，但在上面定义的信号（Signals）却构成了一个拥有良好数学性质的希尔伯特空间，让我们依然可以用线性代数和泛函分析的工具来处理它们。\n例如，在图像处理中，数据通常被表示为定义在二维欧几里得空间 $\\mathbb{R}^2$ 上的信号（像素值）。这种空间具有平移和旋转对称性，这意味着如果我们平移或旋转图像，其内容和结构保持不变。卷积神经网络（CNN）正是利用了这种平移对称性，通过共享权重来捕捉局部特征，从而提高了学习效率和泛化能力。\n对称性与不变性 在机器学习中，对称性指的是数据或任务在某些变换下保持不变的性质。这些变换可以是平移、旋转、缩放等。 例如，在图像分类任务中，如果我们对图像进行平移或旋转，图像的类别通常不会改变。这种不变性是我们希望模型能够捕捉和利用的。\n对称群 对称性可以通过群论来形式化。一个群是一个集合，配备有一个二元运算，满足封闭性、结合性、单位元和逆元等性质。\n对称操作构成一个群，称为对称群，证明如下：\n封闭性：如果 $g_1$ 和 $g_2$ 是对称操作，那么它们的组合 $g_1 \\circ g_2$ 也是一个对称操作，因为连续应用两个对称变换仍然保持数据的不变性。 结合性：如果 $g_1$ 和 $g_2$ 是对称操作，那么对于任何 $g_3$，都有 $(g_1 \\circ g_2) \\circ g_3 = g_1 \\circ (g_2 \\circ g_3)$，因为变换的顺序不会影响最终结果。 单位元：存在一个单位操作 $e$，使得对于任何对称操作 $g$，都有 $e \\circ g = g \\circ e = g$。这个单位操作对应于不进行任何变换。 逆元：对于每个对称操作 $g$，存在一个逆操作 $g^{-1}$，使得 $g \\circ g^{-1} = g^{-1} \\circ g = e$。这个逆操作对应于撤销变换。 注意：$g \\circ h$ 表示先应用变换 $g$，再应用变换 $h$。\n下面以等边三角行为例说明对称群的概念： 在这个例子中，等边三角形的对称群包含六个元素：三个旋转操作（0度、120度、240度）和三个反射操作（通过每个顶点的垂直线）。这些操作满足群的四个性质，因此构成一个群，称为 $D_3$，即三角形的二面体群。 数学上，我们可以把这种操作看做映射： $$g: \\mathcal{X} \\rightarrow \\mathcal{X}$$ 其中 $\\mathcal{X}$ 是数据空间。对于一个对称群 $G$中的每个元素 $g \\in G$，我们都有一个对应的映射 $g$。 例如，$D_3$同样可以表示为矩阵群： $$ D_3 = \\left\\{ \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 2 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 3 \u0026amp; 1 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 1 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 3 \u0026amp; 2 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 3 \\end{pmatrix}, \\begin{pmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{pmatrix} \\right\\} $$\n参考资料 Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., \u0026amp; Vandergheynst, P. (2017). Geometric deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine, 34(4), 18-42. Goodfellow, I., Bengio, Y., \u0026amp; Courville, A. (2016). Deep learning. MIT press. Cohen, T. S., \u0026amp; Welling, M. (2016). Group equivariant convolutional networks. In International conference on machine learning (pp. 2990-2999). PMLR. Kondor, R., \u0026amp; Trivedi, S. (2018). On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International conference on machine learning (pp. 2747-2755). PMLR. Wood, T., \u0026amp; Shawe-Taylor, J. (1996). Representation theory and invariant neural networks. Neural computation, 8(5), 1003-1013. Mallat, S. (2016). Understanding deep convolutional networks. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150203. Lee, J. M. (2013). Introduction to smooth manifolds. Springer Science \u0026amp; Business Media. ","permalink":"http://localhost:1313/zh/posts/geometric_deeplearning/","summary":"\u003ch2 id=\"几何深度学习的演变\"\u003e几何深度学习的演变\u003c/h2\u003e\n\u003cp\u003e几千年来，几何学一直是人类知识的基本组成部分。古希腊人通过欧几里得的《几何原本》将几何学研究形式化。欧几里得的垄断地位在十九世纪结束了，罗巴切夫斯基、波尔约、高斯和黎曼等人分别构建了非欧几里得几何。\u003c/p\u003e\n\u003cp\u003e到了那个世纪末，这些研究已经分化成不同的领域，数学家和哲学家们争论这些几何的有效性和相互关系，以及“唯一真实几何”的本质。\u003c/p\u003e\n\u003cp\u003e年轻的数学家菲利克斯·克莱因指出了摆脱这种困境的出路。克莱因提议将几何学作为不变量的研究，即在某类变换（称为几何的对称性）下保持不变的性质。这种方法通过表明当时已知的各种几何可以通过选择适当的对称变换来定义（使用群论语言形式化），从而创造了清晰度。\u003c/p\u003e\n\u003ch2 id=\"深度学习简介\"\u003e深度学习简介\u003c/h2\u003e\n\u003cp\u003e深度学习的本质建立在两个简单的算法原则之上：第一，表示或特征学习的概念，即适应性的、通常是分层的特征捕捉每个任务的适当规律性概念；第二，通过局部梯度下降进行学习，通常实现为反向传播。\u003c/p\u003e\n\u003ch2 id=\"几何深度学习的目标\"\u003e几何深度学习的目标\u003c/h2\u003e\n\u003cp\u003e虽然在高维空间学习通用函数是一个棘手的估计问题，但大多数任务并不是通用的，且带有源于物理世界底层低维性和结构的基本预定义规律。\u003c/p\u003e\n\u003cp\u003e这种“几何统一”的努力具有双重目的：一方面，它提供了一个通用的数学框架来研究最成功的神经网络架构，如 CNN、RNN、GNN 和 Transformer。另一方面，它提供了一个建设性的程序，将先验物理知识融入神经架构，并为构建尚未发明的未来架构提供了原则性的方法。\u003c/p\u003e\n\u003ch2 id=\"高维学习\"\u003e高维学习\u003c/h2\u003e\n\u003cp\u003e监督机器学习，在其最简单的形式化中，考虑一组 N 个观测值 $D = {(x_i, y_i)}_{i=1}^N$，这些观测值是从定义在 $\\mathcal{X} \\times \\mathcal{Y}$ 上的底层数据分布 P 中独立同分布 (i.i.d.) 抽取的。\u003c/p\u003e\n\u003cp\u003e让我们进一步假设标签 y 是由未知函数 f 生成的，使得 $y_i = f(x_i)$，并且学习问题简化为使用参数化函数类 $F = {f_\\theta \\in \\Theta}$ 来估计函数 f。\u003c/p\u003e\n\u003cp\u003e现代深度学习系统通常在所谓的插值机制中运行，其中估计的 $\\widetilde{f}$ $\\in F$ 满足 $\\widetilde{f}(x_i) = f(x_i)$ 对于所有 $i = 1, . . . , N$。\u003c/p\u003e\n\u003cp\u003e学习算法的性能是根据从 $P$ 中抽取的样本的预期性能来衡量的，使用损失函数$L(.,.)$：\n$$\\mathcal{R} = \\mathbb{E}_{(x,y) \\sim P}[L(\\widetilde{f}(x), f(x))]$$\u003c/p\u003e\n\u003cp\u003e这样构建出来的函数几乎可以逼近一切的函数(通用逼近定理)，但这并不意味着我们不需要用归纳偏置来约束学习问题。给定一个具有通用逼近能力的函数类$\\mathcal{F}$,我们可以定义一个复杂度函数:\n$$c: \\mathcal{F} \\rightarrow \\mathbb{R}$$,将我们的插值问题定义为：\n$$\\widetilde{f} = \\arg\\min_{g \\in \\mathcal{F}} c(g) \\quad s.t. \\quad \\widetilde{f}(x_i) = f(x_i), \\quad i = 1, . . . , N$$\u003c/p\u003e","title":"几何深度学习简介"},{"content":"简介 强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\n策略与行动 智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\n目标 智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\n$$\r\\begin{aligned}\rV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\\end{aligned}\r$$\r其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。 期望是关于：\n$$\r\\begin{aligned}\rp(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\\end{aligned}\r$$\r其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\n周期性任务与持续性任务 如果智能体可能永远与环境交互，我们称之为持续性任务。 或者，如果智能体的交互在系统进入终止状态或吸收状态后终止，我们说智能体处于周期性任务中。\n我们将时间 t 的状态回报定义为未来获得的预期奖励的总和，其中每个奖励乘以折扣因子 $\\gamma$：\n$$\r\\begin{aligned}\rG_t \u0026= R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots \\\\\r\u0026= \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} \\\\\r\u0026= R_{t} + \\gamma G_{t+1}\r\\end{aligned}\r$$\r架构概览 智能体和环境在每个时间步 t 交互如下：\n智能体有一个内部状态 $z_t$，总结了直到时间 t 与环境交互的历史。 智能体根据其策略 $\\pi(z_t)$ 选择一个行动 $a_t$，这意味着 $a_t \\sim \\pi(z_t)$。 然后它通过预测函数 P 预测下一个状态 $z_{t+1|t}$：$z_{t+1|t} = P(z_t, a_t)$ 并可选地预测结果观测 $\\hat{o}{t+1|t} = O(z{t+1|t})$。 环境具有隐藏状态 $w_t$，智能体无法直接观察到。 环境根据其动力学转换到新状态 $w_{t+1}$：$w_{t+1} \\sim M(w_t, a_t)$。 环境生成观测 $o_{t+1} \\sim O(w_{t+1})$，并将其发送回智能体。 ","permalink":"http://localhost:1313/zh/posts/reinforcement_learning01/","summary":"\u003ch2 id=\"简介\"\u003e简介\u003c/h2\u003e\n\u003cp\u003e强化学习 (RL) 是一种机器学习类型，其中智能体通过在环境中采取行动来学习做出决策，以最大化某种累积奖励的概念。与从标记数据集学习模型的监督学习不同，RL 依赖于来自环境的奖励或惩罚形式的反馈。\u003c/p\u003e\n\u003ch2 id=\"策略与行动\"\u003e策略与行动\u003c/h2\u003e\n\u003cp\u003e智能体维护一个内部状态 $z_t$，并将其传递给策略 $\\pi$ 以选择行动 $a_t = \\pi(z_t)$。\u003c/p\u003e\n\u003ch2 id=\"目标\"\u003e目标\u003c/h2\u003e\n\u003cp\u003e智能体的目标是选择一个策略 π，以最大化预期奖励的总和：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\nV^\\pi(s_0) = \\mathbb{E}_{a_0, s_1, a_1, \\dots, a_T, s_T \\sim p(\\cdot \\mid s_0, \\pi)} \\left[ \\sum_{t=0}^T R(s_t, a_t) \\right]\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $s_0$ 是初始状态，$p(\\cdot|s_0, \\pi)$ 是策略 π 从状态 $s_0$ 开始诱导的轨迹分布，$R(s_t, a_t)$ 是在状态 $s_t$ 采取行动 $a_t$ 后收到的奖励。\n期望是关于：\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\n\\begin{aligned}\r\np(a_0, s_1, a_1, \\dots, a_T, s_T \\mid s_0, \\pi) \r\n\u0026= \\pi(a_0 \\mid s_0) p_{env}(o_1 \\mid a_0) \\vartheta(s_1 = U(s_0, a_0, o_1)) \\\\\r\n\u0026= \\prod_{t=1}^T \\pi(a_t \\mid s_t) p_{env}(o_{t+1} \\mid a_t) \\vartheta(s_{t+1} = U(s_t, a_t, o_{t+1}))\r\n\\end{aligned}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e其中 $p_{env}(o_{t+1} \\mid a_t)$ 是环境的观测模型，$U(s_t, a_t, o_{t+1})$ 是基于当前状态、采取的行动和收到的观测的状态更新函数。\u003c/p\u003e","title":"强化学习简介"},{"content":"本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\n拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\n许多种群方法本质上是随机的，并且通常很容易并行化计算。\n种群迭代 种群方法迭代地改进 m 个设计的种群\n$$\rx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r$$\r特定迭代中的种群被称为一代。\n算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\n本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\n种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\nabstract type PopulationMethod end function population_method(M::PopulationMethod, f, desings, k_max) population = init!(M,f,designs) for k in 1:k_max population = iterate!(M, f, population) end return population end 以下是用于生成初始种群的分布：\n均匀分布 (Uniform Distribution) 正态分布 (Normal Distribution) 柯西分布 (Cauchy Distribution) 遗传算法 遗传算法受到生物进化中自然选择过程的启发。\n与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\nstruct GeneticAlgorithm \u0026lt;: PopulationMethod S # SelectionMethod C # CrossoverMethod U # MutationMethod end init!(M::GeneticAlgorithm, f, designs) = designs function step!(M::GeneticAlgorithm, f, population) S, C, U = M.S, M.C, M.U parents = select(S, f.(population)) children = [crossover(C,population[p[1]],population[p[2]]) for p in parents] return [mutate(U, c) for c in children] end 选择 选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\n基于排名的选择根据个体的适应度对其进行排序，并相应地分配选择概率。 锦标赛选择随机选择一个个体子集，并选择其中适应度最高的作为父母。 轮盘赌选择分配与适应度成比例的选择概率，使适应度较高的个体有更高的被选中机会。 abstract type SelectionMethod end # Pick pairs randomly from top k parents struct TruncationSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TruncationSelection, y) p = sortperm(y) return [p[rand(1:t.k, 2)] for i in y] end # Pick parents by choosing best among random subsets struct TournamentSelection \u0026lt;: SelectionMethod k # top k to keep end function select(t::TournamentSelection, y) getparent() = begin p = randperm(length(y)) p[argmin(y[p[1:t.k]])] end return [[getparent(), getparent()] for i in y] end # Sample parents proportionately to fitness struct RouletteWheelSelection \u0026lt;: SelectionMethod end function select(::RouletteWheelSelection, y) y = maximum(y) .- y cat = Categorical(normalize(y, 1)) return [rand(cat, 2) for i in y] end 交叉 交叉结合父母的染色体以形成后代。与选择一样，有几种交叉方案\n在单点交叉中，选择一个随机交叉点，并交换父母染色体的片段以创建后代。 在两点交叉中，选择两个交叉点，并交换这些点之间的片段。 在均匀交叉中，每个基因以相等的概率独立地从父母之一中选择。 abstract type CrossoverMethod end struct SinglePointCrossover \u0026lt;: CrossoverMethod end function crossover(::SinglePointCrossover, a, b) i = rand(eachindex(a)) return [a[1:i]; b[i+1:end]] end struct TwoPointCrossover \u0026lt;: CrossoverMethod end function crossover(::TwoPointCrossover, a, b) n = length(a) i, j = rand(1:n, 2) if i \u0026gt; j (i,j) = (j,i) end return [a[1:i]; b[i+1:j]; a[j+1:n]] end struct UniformCrossover \u0026lt;: CrossoverMethod p # crossover probability end function crossover(U::UniformCrossover, a, b) return [rand() \u0026gt; U.p ? u : v for (u,v) in zip(a,b)] end struct InterpolationCrossover \u0026lt;: CrossoverMethod λ # interpolant end crossover(C::InterpolationCrossover, a, b) = (1-C.λ)*a + C.λ*b 变异 变异引入随机变化以保持种群内的遗传多样性。常见的变异方法是零均值高斯分布。\nabstract type MutationMethod end struct DistributionMutation \u0026lt;: MutationMethod λ # mutation rate D # mutation distribution end function mutate(M::DistributionMutation, child) return [rand() \u0026lt; M.λ ? v + rand(M.D) : v for v in child] end GaussianMutation(σ) = DistributionMutation(1.0, Normal(0,σ)) 染色体中的每个基因通常有很小的概率 λ 发生改变。对于具有 m 个基因的染色体，此变异率通常设置为 λ = 1/m，平均每个子染色体产生一个变异。\n差分进化 差分进化 (DE) 是一种基于种群的优化算法，利用向量差分来扰动种群成员。\n对于每个个体 x：\n从种群中选择三个不同的个体 a、b 和 c。 通过将 b 和 c 之间的加权差添加到 a 来生成试验向量： $$ v = a + F \\cdot (b - c) $$ 其中 F 是缩放因子，通常在 [0, 2] 范围内。 评估试验向量 v 的适应度。如果 v 的适应度优于 x，则在下一代中用 v 替换 x；否则，保留 x。 mutable struct DifferentialEvolution \u0026lt;: PopulationMethod p # crossover probability w # differential weight end init!(M::DifferentialEvolution, f, designs) = designs function step!(M::DifferentialEvolution, f, population) p, w = M.p, M.w n, m = length(population[1]), length(population) for x in population a, b, c = sample(population, 3, replace=false) z = a + w*(b-c) x′ = crossover(UniformCrossover(p), x, z) if f(x′) \u0026lt; f(x) x .= x′ end end return population end 粒子群优化 粒子群优化引入动量以加速向最小值的收敛。种群中的每个个体（或粒子）都会跟踪其当前位置、速度以及迄今为止看到的最佳位置。动量允许个体在有利方向上积累速度，而不受局部扰动的影响。\n在每次迭代中，每个个体都会加速向其看到的最佳位置以及任何个体迄今为止找到的最佳位置移动。加速度由随机项加权。\nmutable struct Particle x # position v # velocity x_best # best design thus far end mutable struct ParticleSwarm \u0026lt;: PopulationMethod w # inertia c1 # first momentum coefficient c2 # second momentum coefficient V # initial particle velocity distribution best # best overall design thus far, and its value end function init!(M::ParticleSwarm, f, designs) population = [Particle(x,rand(M.V),copy(x)) for x in designs] best = (x=copy(population[1].x), y=Inf) for P in population y = f(P.x) if y \u0026lt; best.y; best = (x=P.x, y=y); end end M.best = best return population end function step!(M::ParticleSwarm, f, population) w, c1, c2, best = M.w, M.c1, M.c2, M.best n = length(best.x) for P in population r1, r2 = rand(n), rand(n) P.x += P.v P.v = w*P.v + c1*r1.*(P.x_best - P.x) + c2*r2.*(best.x - P.x) y = f(P.x) if y \u0026lt; best.y; best = (x=copy(P.x), y=y); end if y \u0026lt; f(P.x_best); P.x_best .= P.x; end end M.best = best return population end 萤火虫算法 萤火虫算法的灵感来自于萤火虫闪烁光芒以吸引同种配偶的方式。在萤火虫算法中，种群中的每个个体都是一只萤火虫，可以通过闪光来吸引其他萤火虫。\n在每次迭代中，所有萤火虫都向所有更有吸引力的萤火虫移动。萤火虫的吸引力与其表现成正比。\nstruct Firefly \u0026lt;: PopulationMethod α # walk step size β # source intensity brightness # intensity function end init!(M::Firefly, f, designs) = designs function step!(M::Firefly, f, population) α, β, brightness = M.α, M.β, M.brightness m = length(population[1]) N = MvNormal(I(m)) for a in population, b in population if f(b) \u0026lt; f(a) r = norm(b-a) a .+= β*brightness(r)*(b-a) + α*rand(N) end end return population end 布谷鸟搜索 布谷鸟搜索是另一种受自然启发的算法，以布谷鸟命名，布谷鸟从事一种巢寄生行为。布谷鸟将蛋产在其他鸟类的巢中。\n在布谷鸟搜索中，每个巢代表一个设计点。可以使用来自巢的莱维飞行（Lévy flights）产生新的设计点，这是步长服从重尾分布（通常是柯西分布）的随机游走。\nmutable struct CuckooSearch \u0026lt;: PopulationMethod p_s # search fraction p_a # nest abandonment fraction C # flight distribution end function init!(M::CuckooSearch, f, designs) return [(x=x, y=f(x)) for x in designs] end function step!(M::CuckooSearch, f, population) p_s, p_a, C = M.p_s, M.p_a, M.C m, n = length(population), length(population[1].x) m_search = round(Int, m*p_s) m_abandon = round(Int, m*p_a) for i in 1:m_search j, k = rand(1:m), rand(1:m) x = population[j].x + rand(C,n) y = f(x) if y \u0026lt; population[k].y population[k] = (x=x, y=y) end end p = sortperm(population, by=nest-\u0026gt;nest.y, rev=true) for i in 1:m_abandon j = rand(1:m-m_abandon)+m_abandon x′ = population[p[j]].x + rand(C,n) population[p[i]] = (x=x′, y=f(x′)) end return population end 混合方法 许多种群方法在全局搜索中表现良好，能够避免局部最小值并找到设计空间的最佳区域。不幸的是，与下降方法相比，这些方法在局部搜索中表现不佳。\n已经开发了几种混合方法，将种群方法与基于下降的特征相结合，以提高其在局部搜索中的性能。\n在 拉马克学习 (Lamarckian learning) 中，种群方法扩展了局部搜索方法，该方法局部改进每个个体。原始个体及其目标函数值被个体的优化对应物所取代。 在 鲍德温学习 (Baldwinian learning) 中，相同的局部搜索方法应用于每个个体，但结果仅用于更新个体的目标函数值。个体不会被替换，而只是与优化的目标函数值相关联。 总结 种群方法是强大的优化技术，利用一组设计点来有效地探索设计空间。通过利用受自然过程（如遗传算法、差分进化和粒子群优化）启发的机制，这些方法可以导航复杂的景观并避免局部最小值。结合种群方法和局部搜索技术的混合方法进一步增强了它们的性能，使它们成为解决各种优化问题的通用工具。\n","permalink":"http://localhost:1313/zh/posts/population_method/","summary":"\u003cp\u003e本文介绍各种涉及使用一组设计点（称为个体）进行优化的种群方法。\u003c/p\u003e\n\u003cp\u003e拥有分布在整个设计空间中的大量个体有助于算法更有效地探索设计空间。\u003c/p\u003e\n\u003cp\u003e许多种群方法本质上是随机的，并且通常很容易并行化计算。\u003c/p\u003e\n\u003ch2 id=\"种群迭代\"\u003e种群迭代\u003c/h2\u003e\n\u003cp\u003e种群方法迭代地改进 m 个设计的种群\u003c/p\u003e\n\u003cdiv\u003e\r\n$$\r\nx^{(1)}, x^{(2)}, \\dots, x^{(m)}\r\n$$\r\n\u003c/div\u003e\r\n\u003cp\u003e特定迭代中的种群被称为一代。\u003c/p\u003e\n\u003cp\u003e算法的设计使得种群中的个体在多代后收敛到一个或多个局部最小值。\u003c/p\u003e\n\u003cp\u003e本文讨论的各种方法在如何从当前一代生成新一代方面有所不同。\u003c/p\u003e\n\u003cp\u003e种群方法从初始种群开始，通常是随机生成的。初始种群应分布在设计空间中以鼓励探索。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eabstract type\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e population_method(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e, f, desings, k_max)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e init!(M,f,designs)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e k \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ek_max\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        population \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e iterate!(M, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e population\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以下是用于生成初始种群的分布：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e均匀分布 (Uniform Distribution)\u003c/li\u003e\n\u003cli\u003e正态分布 (Normal Distribution)\u003c/li\u003e\n\u003cli\u003e柯西分布 (Cauchy Distribution)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"Population Initialization\" loading=\"lazy\" src=\"/picture/population_method01.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"遗传算法\"\u003e遗传算法\u003c/h2\u003e\n\u003cp\u003e遗传算法受到生物进化中自然选择过程的启发。\u003c/p\u003e\n\u003cp\u003e与每个个体关联的设计点表示为染色体。在每一代中，适应度较高的个体的染色体通过选择、交叉和变异操作传递给下一代。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-julia\" data-lang=\"julia\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;:\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ePopulationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S \u003cspan style=\"color:#75715e\"\u003e# SelectionMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    C \u003cspan style=\"color:#75715e\"\u003e# CrossoverMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    U \u003cspan style=\"color:#75715e\"\u003e# MutationMethod\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003einit!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, designs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e designs\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e step!(M\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eGeneticAlgorithm\u003c/span\u003e, f, population)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    S, C, U \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eS, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eC, M\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eU\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    parents \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e select(S, f\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003e(population))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    children \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [crossover(C,population[p[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e]],population[p[\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e]])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e parents]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [mutate(U, c) \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e c \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e children]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eend\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"选择\"\u003e选择\u003c/h3\u003e\n\u003cp\u003e选择操作从当前种群中选择个体作为下一代的父母。常见的选择方法包括基于排名的选择、锦标赛选择和轮盘赌选择。\u003c/p\u003e","title":"种群方法"},{"content":"欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\n关于语言 我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\n欢迎留言并分享您的反馈。期待与大家交流！\n写作愉快！\n","permalink":"http://localhost:1313/zh/posts/first-post/","summary":"\u003cp\u003e欢迎来到我的第一篇博客文章！在这里我将分享我的想法、经历和更新。敬请期待更多内容！\u003c/p\u003e\n\u003ch2 id=\"关于语言\"\u003e关于语言\u003c/h2\u003e\n\u003cp\u003e我将主要用中文撰写文章，以触达更广泛的受众。不过，为了清晰起见，我可能会在必要时包含英文术语和短语。当然，未来也可能会提供部分文章的英文版本。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e欢迎留言并分享您的反馈。期待与大家交流！\u003c/p\u003e\n\u003cp\u003e写作愉快！\u003c/p\u003e","title":"第一篇文章"}]